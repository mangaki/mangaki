{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks for cold-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to compare DPP / random / mosaïque for the selection of the first items to rate for a newcomer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries: DPP sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load vectors from the saved SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mangaki.utils.data import Dataset\n",
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mangaki.utils.svd import MangakiSVD\n",
    "algo = MangakiSVD()\n",
    "algo.load(algo.get_backup_filename())  # Trained on everything\n",
    "dataset.load('ratings-' + algo.get_backup_filename())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rated_by_jj = np.array(User.objects.get(id=1).rating_set.values_list('work', 'work__title', 'choice'), dtype=[('work_id', 'i2'), ('work_title', 'U128'), ('choice', 'S8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rated_works = rated_by_jj['work_id']\n",
    "encoded_work_ids = dataset.encode_works(rated_works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectors = algo.VT.T[encoded_work_ids]\n",
    "L = vectors.dot(vectors.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D, V = np.linalg.eig(L.T)\n",
    "D = np.real(D)\n",
    "V = np.real(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to summarize JJ's profile, which ratings should we keep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(  34, 'K-On!', b'wontsee') (   9, 'Elfen Lied', b'willsee')\n",
      " ( 150, 'Danshi Koukousei no Nichijou', b'willsee')\n",
      " (1973, 'Fate/stay night: Unlimited Blade Works (TV) - Prologue', b'willsee')\n",
      " (1563, 'Ponyo sur la falaise', b'like')]\n"
     ]
    }
   ],
   "source": [
    "from mangaki.utils import dpplib\n",
    "sampled_indices = list(map(int, dpplib.sample_k(5, D, V)))\n",
    "print(rated_by_jj[sampled_indices])\n",
    "dpp_works = rated_works[sampled_indices]\n",
    "\n",
    "def get_dpp_works(k):\n",
    "    sampled_indices = list(map(int, dpplib.sample_k(k, D, V)))\n",
    "    # print(rated_by_jj[sampled_indices])\n",
    "    return rated_works[sampled_indices]\n",
    "\n",
    "import random\n",
    "def get_random_works(k):\n",
    "    return np.array(random.sample(list(rated_works), k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536 ratings for JJ\n"
     ]
    }
   ],
   "source": [
    "print(Rating.objects.filter(user_id=1).count(), 'ratings for JJ')\n",
    "ds = Dataset()\n",
    "anonymized = ds.make_anonymous_data(Rating.objects.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_works_to_rate():\n",
    "    if METHOD == 'dpp':\n",
    "        kept_works = get_dpp_works(NB_WORKS)\n",
    "    else:\n",
    "        kept_works = get_random_works(NB_WORKS)\n",
    "    return kept_works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_train_test(kept_works):\n",
    "    i_train = []\n",
    "    i_test = []\n",
    "    my_encoded_user_id = ds.encode_user[1]\n",
    "    encoded_kept_works = set(ds.encode_works(kept_works))\n",
    "    for i, (encoded_user_id, encoded_work_id) in enumerate(anonymized.X):\n",
    "        if encoded_user_id == my_encoded_user_id and encoded_work_id not in encoded_kept_works:\n",
    "            i_test.append(i)\n",
    "        else:\n",
    "            i_train.append(i)\n",
    "    return i_train, i_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mangaki.utils.knn import MangakiKNN\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def compute_error(i_train, i_test):\n",
    "    knn = MangakiKNN(40)\n",
    "    knn.set_parameters(anonymized.nb_users, anonymized.nb_works)\n",
    "    knn.fit(anonymized.X[i_train], anonymized.y[i_train])\n",
    "    my_encoded_user_id = ds.encode_user[1]\n",
    "    neighbors = knn.get_neighbors([my_encoded_user_id])[0]\n",
    "    # print([User.objects.get(id=user_id) for user_id in ds.decode_users(neighbors)])\n",
    "    y_pred = knn.predict(anonymized.X[i_test])\n",
    "    print('predicted:', y_pred[:5])\n",
    "    print('was:', anonymized.y[i_test][:5])\n",
    "    rmse = mean_squared_error(anonymized.y[i_test], y_pred) ** 0.5\n",
    "    print('rmse:', rmse)\n",
    "    top_pred_indices = y_pred.argsort()[-20:]\n",
    "    # top_pred_indices = anonymized.y[i_test].argsort()[-20:]\n",
    "    print('predicted:', y_pred[top_pred_indices])\n",
    "    print('was:', anonymized.y[i_test][top_pred_indices])\n",
    "    rmse = mean_squared_error(anonymized.y[i_test][top_pred_indices], y_pred[top_pred_indices]) ** 0.5\n",
    "    print('rmse:', rmse)\n",
    "    for work_id in [ds.decode_work[encoded_work_id] for _, encoded_work_id in anonymized.X[i_test][top_pred_indices]]:\n",
    "        print(Work.objects.get(id=work_id).title)\n",
    "    # print('full predict')\n",
    "    # knn.predict(np.array([(1522, ds.encode_work[13811])]), True)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_simulation():\n",
    "    kept_works = select_works_to_rate()\n",
    "    i_train, i_test = split_train_test(kept_works)\n",
    "    print('train size', len(i_train))\n",
    "    print('test size', len(i_test))\n",
    "    rmse = compute_error(i_train, i_test)\n",
    "    print(NB_WORKS, METHOD, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results (number of works asked, strategy, RMSE)\n",
    "\n",
    "- 10 DPP 1.09488816919 1.1020390692\n",
    "- 20 DPP 1.0957652159900086\n",
    "- 50 DPP 1.06436560838\n",
    "- 100 DPP 1.0724727205\n",
    "- 500 DPP 1.27818830679 0.848657862475 (possibly overfitting)\n",
    "\n",
    "- 10 RND 1.09689215268 1.08273857127\n",
    "- 20 RND 1.11930399192\n",
    "- 50 RND 1.06455730002\n",
    "- 100 RND 1.06357987938\n",
    "- 500 RND 0.825381153284 0.754057572138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_WORKS = 10\n",
    "METHOD = 'dpp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 317355\n",
      "test size 526\n",
      "[array([ 855,  279, 1050,  873, 1155, 1799,  103,  893, 1892,  745, 1761,\n",
      "       1235,  101, 1239,  406, 1567,  634, 1441,  438, 1244, 1134, 1664,\n",
      "        610,  169,  912, 1222,  129, 1687,  159,  407,  758,  593,  962,\n",
      "        551, 1323,  785,  570, 1485, 1814, 1401])]\n",
      "predicted: [ 0.  0.  0.  0.  0.]\n",
      "was: [-0.5 -0.5 -0.5  0.5  0.5]\n",
      "rmse: 1.23206181617\n",
      "predicted: [ 1.14453807  1.14509658  1.15560294  1.16562679  1.20279494  1.22436833\n",
      "  1.22739906  1.26143443  1.26331597  1.2685274   1.31005521  1.31468137\n",
      "  1.39853659  1.42103941  1.43096924  1.6688064   1.68547088  1.70220729\n",
      "  1.72033654  1.72612439]\n",
      "was: [ 0.5  2.   2.  -0.5  4.   0.5  4.   2.   2.   2.   2.   0.5  0.1  4.   2.\n",
      "  0.5  0.5  2.   4.   2. ]\n",
      "rmse: 1.41820288426\n",
      "Angel Beats!\n",
      "Mahou Shoujo Madoka★Magica\n",
      "Toki wo Kakeru Shoujo\n",
      "Kill la Kill\n",
      "Suzumiya Haruhi no Yuuutsu\n",
      "Fullmetal Alchemist\n",
      "Les Enfants Loups : Ame & Yuki\n",
      "Code Geass: Hangyaku no Lelouch R2\n",
      "Durarara!!\n",
      "Nausicaä of the Valley of the Wind\n",
      "Le Château dans le ciel\n",
      "Psycho-Pass\n",
      "Mon voisin Totoro\n",
      "No Game No Life\n",
      "Le Château ambulant\n",
      "FullMetal Alchemist\n",
      "Fullmetal Alchemist: Brotherhood\n",
      "Death Note\n",
      "Princesse Mononoké\n",
      "L'Attaque des Titans\n",
      "10 dpp 1.41820288426\n"
     ]
    }
   ],
   "source": [
    "run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still needs to be done:\n",
    "- run simulation on several users (how many works should be kept?)\n",
    "- try a different number of neighbors\n",
    "- should we evaluate the strategy on the whole profile or just the top recommendations?\n",
    "- try other models than MangakiKNN (but others are slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_user_id = dataset.encode_work[1]\n",
    "X_test = np.array([(encoded_user_id, dataset.encode_work[work_id]) for work_id in rated_works])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Death Note', b'like')\n",
      "(13, 'Code Geass: Hangyaku no Lelouch R2', b'like')\n",
      "(2, 'Code Geass: Hangyaku no Lelouch', b'neutral')\n",
      "(5, \"L'Attaque des Titans\", b'like')\n",
      "(127, 'Hunter x Hunter', b'wontsee')\n",
      "(2417, \"Kuroko's Basketball 2\", b'willsee')\n",
      "(9385, 'Parasyte -the maxim-', b'willsee')\n",
      "(107, 'Kuroko no Basket', b'willsee')\n",
      "(7, 'Fullmetal Alchemist: Brotherhood', b'willsee')\n",
      "(46, 'Psycho-Pass', b'willsee')\n"
     ]
    }
   ],
   "source": [
    "y_pred = algo.predict(X_test)\n",
    "top_recommended = y_pred.argsort()[-10:]\n",
    "for i in top_recommended:\n",
    "    print(rated_by_jj[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   1,   13,    2,    5,  127, 2417, 9385,  107,    7,   46], dtype=int16),\n",
       " array([ 1.6811598 ,  1.76624399,  1.76966227,  1.83171241,  1.85026713,\n",
       "         1.8516618 ,  1.90392899,  2.01091566,  2.07686592,  2.4513739 ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rated_works[top_recommended], y_pred[top_recommended]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mangaki.utils.values import rating_values\n",
    "y_test = np.array(list(map(lambda x: rating_values[x.decode('utf-8')], rated_by_jj['choice'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3342711646750836"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jin/Sites/mangaki/venv/lib/python3.6/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reg = algo.VT.T[dataset.encode_works(rated_works)]\n",
    "clf.fit(X_reg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0812074357558288"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reg_pred = clf.predict(X_reg)\n",
    "rmse = mean_squared_error(y_test, y_reg_pred) ** 0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 171, 153, 250, 373, 251, 306, 442, 272, 291, 20, 331, 200, 301, 395, 341, 286, 375, 38, 258]\n"
     ]
    }
   ],
   "source": [
    "sampled_indices = list(map(int, dpplib.sample_k(20, D, V)))\n",
    "print(sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9427890870750679"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression(fit_intercept=False)\n",
    "clf.fit(X_reg[sampled_indices], y_test[sampled_indices])\n",
    "y_reg_pred = clf.predict(X_reg)\n",
    "rmse = mean_squared_error(y_test, y_reg_pred) ** 0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(  16, 'Steins;Gate', b'favorite') (  19, 'Mirai Nikki', b'willsee')\n",
      " (  46, 'Psycho-Pass', b'willsee') (  55, 'No Game No Life', b'favorite')\n",
      " (4369, \"Attaque Des Titans (l')\", b'willsee')\n",
      " (5001, 'Death note', b'like') (   1, 'Death Note', b'like')\n",
      " (   2, 'Code Geass: Hangyaku no Lelouch', b'neutral')\n",
      " (  13, 'Code Geass: Hangyaku no Lelouch R2', b'like')\n",
      " (   5, \"L'Attaque des Titans\", b'like')]\n",
      "[(    8, 'Fullmetal Alchemist', b'willsee')\n",
      " (  195, 'Fullmetal Alchemist: Brotherhood OVA Collection', b'willsee')\n",
      " (   18, 'Fairy Tail', b'willsee')\n",
      " (    7, 'Fullmetal Alchemist: Brotherhood', b'willsee')\n",
      " (   17, 'Naruto: Shippuuden', b'wontsee')\n",
      " (  126, 'Dragon Ball GT', b'willsee')\n",
      " (  125, 'Fullmetal Alchemist: The Conqueror of Shamballa', b'willsee')\n",
      " (   27, 'One Piece', b'wontsee') (10505, 'Dog Days', b'willsee')\n",
      " (  844, 'Card Captor Sakura', b'favorite')]\n"
     ]
    }
   ],
   "source": [
    "top_recommended = y_reg_pred.argsort()[-10:]\n",
    "print(rated_by_jj[top_recommended])\n",
    "bottom_recommended = y_reg_pred.argsort()[:10]\n",
    "print(rated_by_jj[bottom_recommended])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3143075293148456"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = random.sample(range(len(rated_works)), 10)\n",
    "clf = LinearRegression(fit_intercept=False)\n",
    "clf.fit(X_reg[sampled_indices], y_test[sampled_indices])\n",
    "y_reg_pred = clf.predict(X_reg)\n",
    "rmse = mean_squared_error(y_test, y_reg_pred) ** 0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clean SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mangaki.utils.data import Dataset\n",
    "dataset = Dataset()\n",
    "dataset.load('ratings-svd.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mangaki.utils.svd import MangakiSVD\n",
    "model = MangakiSVD(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "i_train, i_test = train_test_split(range(dataset.anonymized.nb_users), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "1990 1986\n"
     ]
    }
   ],
   "source": [
    "print(min(i_train), min(i_test))\n",
    "print(max(i_train), max(i_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20601420028249565\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "r_train = []\n",
    "r_test = []\n",
    "test_set = set(i_test)\n",
    "nb_ratings = Counter()\n",
    "for r, (encoded_user_id, encoded_work_id) in enumerate(dataset.anonymized.X):\n",
    "    if encoded_user_id in test_set:\n",
    "        r_test.append(r)\n",
    "    else:\n",
    "        r_train.append(r)\n",
    "        nb_ratings[encoded_work_id] += 1\n",
    "print(len(r_test) / len(dataset.anonymized.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "popular_encoded_work_ids = []\n",
    "for encoded_work_id, _ in nb_ratings.most_common(100):\n",
    "    popular_encoded_work_ids.append(encoded_work_id)\n",
    "popular_encoded_work_ids = np.array(popular_encoded_work_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "truth = defaultdict(dict)\n",
    "for r in r_test:\n",
    "    user_id, work_id = dataset.anonymized.X[r]\n",
    "    truth[user_id][work_id] = dataset.anonymized.y[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing M: (1991 × 9256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jin/Sites/mangaki/mangaki/mangaki/utils/svd.py:41: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  means[i] = np.sum(matrix[i]) / np.sum(matrix[i] != 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrono: fill and center matrix [0q, 3690ms]\n",
      "Shapes (1991, 20) (20,) (20, 9256)\n",
      "Chrono: factor matrix [0q, 1424ms]\n"
     ]
    }
   ],
   "source": [
    "model.set_parameters(dataset.anonymized.nb_users, dataset.anonymized.nb_works)\n",
    "model.fit(dataset.anonymized.X[r_train], dataset.anonymized.y[r_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 20, 97, 19, 73]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get popular works\n",
    "vectors = model.VT.T[popular_encoded_work_ids]\n",
    "L = vectors.dot(vectors.T)\n",
    "\n",
    "from mangaki.utils.dpp import MangakiProxyDPP\n",
    "dpp = MangakiProxyDPP(vectors)\n",
    "\n",
    "sampled_indices = list(map(int, dpp.sample_k(5)))\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "user_id = i_test[0]\n",
    "sampled_indices = list(map(int, dpp.sample_k(10)))\n",
    "asked_encoded_work_ids = popular_encoded_work_ids[sampled_indices]\n",
    "X = []\n",
    "y = []\n",
    "for encoded_work_id in asked_encoded_work_ids:\n",
    "    choice = truth[user_id].get(encoded_work_id)\n",
    "    if choice is not None:\n",
    "        X.append(model.VT.T[encoded_work_id])\n",
    "        y.append(choice)\n",
    "clf = LinearRegression(fit_intercept=False)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0716876392242831"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_work_ids, true_choices = zip(*truth[user_id].items())\n",
    "encoded_work_ids = list(encoded_work_ids)\n",
    "pred_choices = clf.predict(model.VT.T[encoded_work_ids])\n",
    "model.compute_rmse(pred_choices, true_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29657854  1.59021032  1.09927386  2.          2.38533624]\n",
      "(0.10000000000000001, 2.0, 4.0, 2.0, 2.0)\n"
     ]
    }
   ],
   "source": [
    "print(pred_choices[:5])\n",
    "print(true_choices[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
